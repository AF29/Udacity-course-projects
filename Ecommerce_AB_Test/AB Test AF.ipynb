{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "A/B tests are very commonly performed by data analysts and data scientists.\n",
    "\n",
    "For this project, we will be working to understand the results of an A/B test run by an e-commerce website.  Our goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "random.seed(42)# setting the seed for same answers as the classroom quizzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` a. Read in the dataset and take a look at the top few rows here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"ab_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The number of rows in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_users=df.shape[0]\n",
    "overall_users\n",
    "#We have 294478 rows in this dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. The number of unique users in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_id'].nunique()\n",
    "# We have 290584 unique users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "d. The proportion of users converted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    259241\n",
       "1     35237\n",
       "Name: converted, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.converted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 35173 users converted which represents 11.94%\n"
     ]
    }
   ],
   "source": [
    "converted_users=df.query('converted==1')['user_id'].nunique()\n",
    "proportion=round(converted_users*(100/(overall_users)),2)\n",
    "print('Only '+ str(converted_users) +' users converted which represents '+str(proportion)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "e. The number of times the `new_page` and `treatment` don't line up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('(landing_page == \"new_page\" and group!= \"treatment\") or (landing_page != \"new_page\" and group == \"treatment\")')['user_id'].count()\n",
    "#The number of times the new_page and treatment don't match is 3893. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Th number of rows with missing values(if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().any()\n",
    "#We dont have any missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` For the rows where **treatment** is not aligned with **new_page** or **control** is not aligned with **old_page**, we cannot be sure if this row truly received the new or old page. \n",
    "\n",
    "a. The new **df2** without these rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are now removing the rows where the new_page and treatment don't match.\n",
    "df2=df.drop(df.query('(landing_page == \"new_page\" and group!= \"treatment\") or (landing_page != \"new_page\" and group == \"treatment\")').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should be 0 since all relevant rows were removed .\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.`a. The number of unique **user_id**s in **df2**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['user_id'].nunique()\n",
    "#We have 290584 unique user_id in df2 now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b&c. The repeated **user_id** in **df2** and its row information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2.duplicated(['user_id'],keep=False)]\n",
    "# The repeated user_id is 773192. \n",
    "#Only the timestamp column differs in the two rows otherwise the remaining information is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Dropping one of the repeated row from **df2**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df2.drop(df2[(df2.user_id==773192) & (df2.timestamp=='2017-01-14 02:55:59.590927') ].index)\n",
    "df2[df2['user_id']==773192]\n",
    "#We dropped the row with index 2893."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Let now start calculating the probablities.\n",
    "a. The probability of an individual converting regardless of the page they receive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of converting regardless of page is 0.1196 .\n"
     ]
    }
   ],
   "source": [
    "converted_users2=df2.query('converted==1')['user_id'].nunique()\n",
    "converted_prob2=round(converted_users2/df2.shape[0],4)\n",
    "print( 'The probability of converting regardless of page is '+str(converted_prob2)+' .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Given that an individual was in the `control` group, the probability they converted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given that an individual was in the control group, the probability of converting is 0.1204 .\n"
     ]
    }
   ],
   "source": [
    "converted_control_users2=df2.query('converted==1 and group ==\"control\"')['user_id'].nunique()\n",
    "control_users2=df2.query('group ==\"control\"')['user_id'].nunique()\n",
    "prob_control2=round(converted_control_users2/control_users2,4)\n",
    "print('Given that an individual was in the control group, the probability of converting is '+str(prob_control2)+' .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Given that an individual was in the `treatment` group, the probability they converted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given that an individual was in the treatment group, the probability of converting is 0.1188 .\n"
     ]
    }
   ],
   "source": [
    "converted_treat_users2=df2.query('converted==1 and group ==\"treatment\"')['user_id'].nunique()\n",
    "treat_users2=df2.query('group ==\"treatment\"')['user_id'].nunique()\n",
    "prob_treat2=round(converted_treat_users2/treat_users2,4)\n",
    "print('Given that an individual was in the treatment group, the probability of converting is '+str(prob_treat2)+' .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. The probability that an individual received the new page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of receiving the new page is 0.5001 .\n"
     ]
    }
   ],
   "source": [
    "newpage_users= df2.query('landing_page==\"new_page\"')['user_id'].nunique()\n",
    "prob_newpage2=round(newpage_users/df2.shape[0],4)\n",
    "print('The probability of receiving the new page is '+str(prob_newpage2)+' .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Observation on our results from a through d ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that:\n",
    "\n",
    "1. The probability of converting regardless of page is 0.1196 .\n",
    "\n",
    "2. Given that an individual was in the control group, the probability of converting is 0.1204 .\n",
    "\n",
    "3. Given that an individual was in the treatment group, the probability of converting is 0.1188 .\n",
    "\n",
    ">We are getting approximately the same probability regardless wherether we are in the control or treatement group which explain why our overall conversion propability regardless of the page is ~0.12 too.We conclude that there isnt sufficient evidence to say that the new treatment page leads to more conversions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "We notice that because of the time stamp associated with each event, we could technically run a hypothesis test continuously as each observation was observed.  \n",
    "\n",
    "However, then the hard question is do we stop as soon as one page is considered significantly better than another or does it need to happen consistently for a certain amount of time?  How long do we run to render a decision that neither page is better than another?  \n",
    "\n",
    "These questions are the difficult parts associated with A/B tests in general.  \n",
    "\n",
    "\n",
    "`1.` For now, consider we need to make the decision just based on all the data provided.  If we want to assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%, please see below our null and alternative hypotheses in terms of **$p_{old}$** and **$p_{new}$**, which are the converted rates for the old and new pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Null Hypothese $H_{0}$: $p_{new}$ <= $p_{old}$\n",
    "\n",
    "> Alternative Hypothese $H_{1}$: $p_{new}$ > $p_{old}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Assume under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page. <br><br>\n",
    "\n",
    "We will use a sample size for each page equal to the ones in **ab_data.csv**.  <br><br>\n",
    "\n",
    "We will perform the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null.  <br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. The **convert rate** for $p_{new}$ under the null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1196"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_new=round(df2.query('converted==1')['user_id'].nunique()/df2.shape[0],4)\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The **convert rate** for $p_{old}$ under the null: <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1196"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_old=round(df2.query('converted==1')['user_id'].nunique()/df2.shape[0],4)\n",
    "p_old\n",
    "\n",
    "#Please note we were already aware here that p_old & p_new were equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. The value for $n_{new}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique users with the new page\n",
    "n_new=df2.query('landing_page == \"new_page\"')['user_id'].nunique()\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. The value for $n_{old}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique users with the old page\n",
    "n_old=df2.query('landing_page == \"old_page\"')['user_id'].nunique()\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. We will simulate $n_{new}$ transactions with a convert rate of $p_{new}$ under the null and then store these $n_{new}$ 1's and 0's in **new_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted =np.random.choice([0,1],n_new,p=(p_new,1-p_new))\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. We will simulate $n_{old}$ transactions with a convert rate of $p_{old}$ under the null and then store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_page_converted =np.random.choice([0,1],n_old,p=(p_old,1-p_old))\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. We will compute $p_{new}$ - $p_{old}$ for our simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0006376960633270867"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted.mean()-old_page_converted.mean()\n",
    "#p_new - p_old under the null is ~0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. We will simulate 10,000 $p_{new}$ - $p_{old}$ values using this same process similarly to the one we calculated in parts **a. through g.** above and then store all 10,000 values in a numpy array called **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sampling distribution for difference in completion rates with boostrapping\n",
    "p_diffs = []\n",
    "size = df.shape[0]\n",
    "for _ in range(10000):\n",
    "    samp = df2.sample(size, replace=True)\n",
    "    new_page_converted =np.random.choice([0,1],n_new,p=(p_new,1-p_new))\n",
    "    old_page_converted =np.random.choice([0,1],n_old,p=(p_old,1-p_old))\n",
    "    p_diffs.append(new_page_converted.mean() - old_page_converted.mean())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diffs=np.array(p_diffs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. The histogram of the **p_diffs**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   4.,   61.,  369., 1339., 2544., 2794., 2019.,  686.,  164.,\n",
       "          20.]),\n",
       " array([-0.00478142, -0.00387084, -0.00296026, -0.00204967, -0.00113909,\n",
       "        -0.00022851,  0.00068207,  0.00159265,  0.00250323,  0.00341381,\n",
       "         0.00432439]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs)\n",
    "# This plot is what we expected so we can support our null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. The proportion of the **p_diffs** that are greater than the actual difference observed in **ab_data.csv**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015782389853555567"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing actual observed difference based on actual converted rate\n",
    "convert_new=(df2.query('converted == 1 and landing_page == \"new_page\"')['user_id'].nunique())/n_new\n",
    "convert_old=(df2.query('converted == 1 and landing_page == \"old_page\"')['user_id'].nunique())/n_old\n",
    "observed_diff=convert_new-convert_old\n",
    "observed_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  18.,  138.,  611., 1764., 2723., 2619., 1511.,  503.,  105.,\n",
       "           8.]),\n",
       " array([-4.38136204e-03, -3.49140652e-03, -2.60145100e-03, -1.71149548e-03,\n",
       "        -8.21539958e-04,  6.84155626e-05,  9.58371084e-04,  1.84832660e-03,\n",
       "         2.73828213e-03,  3.62823765e-03,  4.51819317e-03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create distribution under the null hypothesis and plot it\n",
    "dist_under_H0=np.random.normal(0, p_diffs.std(), p_diffs.size)\n",
    "plt.hist(dist_under_H0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9043"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dist_under_H0 > observed_diff).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k. Obervation on part **j.** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We just computed the p-value. The p-value is the probability of getting our statistic or a more extreme value if the null is true.\n",
    "\n",
    "> We observe that $p_{old}$  > $alpha$ with Type I error rate of 5% so we fail to reject $H_{0}$ . \n",
    "\n",
    "> We conclude that the probability of convert rate for the old page is the same as the new page with a 5% Type I error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. We could also use a built-in to achieve similar results per below.  Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1203863045004612, 0.11880806551510564, 145274, 145310)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "convert_old,convert_new,n_old,n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. Now use `stats.proportions_ztest` to compute your test statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0032875796753531767, 0.5013115521701044)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score, p_value = sm.stats.proportions_ztest(np.array([convert_new,convert_old]),np.array([n_new,n_old]), alternative = 'larger')\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49868844782989563"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "norm.cdf(z_score) # the significance of our z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.959963984540054"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.ppf(1-(0.05/2))# our critical value at 95% confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n. Observation on z-score and p-value computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We observe that the z-score is lower than the critical value of ~1.96 so we fail to reject $H_{0}$ .\n",
    "\n",
    ">We conclude that the conversion rates of the old and new pages are the same which agrees with our finding in parts **j.** and **k.** ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "`1.` In this final part, you will see that the result you acheived in the previous A/B test can also be acheived by performing regression.<br><br>\n",
    "\n",
    "a. Type of regression better suited for our case:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We have here categorical variable so we should be performing a logistic regression.\n",
    "\n",
    "> Logistic Regression is a predictive multiple regression outproach used when the dependent variable is binary.It describes data and explains the relationship between one dependent binary variable and one or more independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The goal is to use **statsmodels** to fit the regression model we specified in part **a.** to see if there is a significant difference in conversion based on which page a customer receives.  However, we first need to create a column for the intercept, and create a dummy variable column for which page each user received.  We will add an **intercept** column, as well as an **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= df2.join(pd.get_dummies(df2['landing_page']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>new_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  new_page  old_page  ab_page  \n",
       "0          1         0         1        0  \n",
       "1          1         0         1        0  \n",
       "2          1         1         0        1  \n",
       "3          1         1         0        1  \n",
       "4          1         0         1        0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['ab_page'] = pd.get_dummies(df2['group']) ['treatment']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. We will use **statsmodels** to import your regression model. We will then instantiate the model, and fit the model using the two columns we created in part **b.** to predict whether or not an individual converts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_mod1 = sm.Logit(df2['converted'], df2[['intercept','ab_page']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. The summary of our model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              converted   No. Observations:               290584\n",
      "Model:                          Logit   Df Residuals:                   290582\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sun, 11 Oct 2020   Pseudo R-squ.:               8.077e-06\n",
      "Time:                        23:36:45   Log-Likelihood:            -1.0639e+05\n",
      "converged:                       True   LL-Null:                   -1.0639e+05\n",
      "                                        LLR p-value:                    0.1899\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
      "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "results1 = logit_mod1.fit()\n",
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. The p-value associated with **ab_page**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The p-value associated with ab_page is 0.190 .\n",
    "\n",
    ">In my regression model, $H_{0}$  is that there is no difference between the treatment and control group and $H_{1}$  is that there is a difference between the two groups.\n",
    "\n",
    ">In part II, we have mentioned that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%,which wasnt the case here in our regression model. We have used different explanatory variable in both parts which is the reason behind the difference in p_value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Now, we are considering other things that might influence whether or not an individual converts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We may try to add the influences associated with time(timestamp variable) on conversion. We can explore whether the conversion rate depends on on a specific time or day in the week where people tend to look through the website. We can convert this field into a categorical field where we will have only four aspects of time (Morning,Afternoon,Evening and Night).\n",
    "\n",
    ">Please note that adding more terms will make our model more complex and take away the ease of interpreting coefficients. We could also experience seeing some of the new terms dependable on the independent variable  which would require higher order terms to improve the performance of our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Now along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives. We will need to read in the **countries.csv** dataset and merge together our datasets on the approporiate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>new_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834778</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-14 23:08:43.304998</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928468</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-23 14:44:16.387854</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822059</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 14:04:14.719771</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711597</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-22 03:14:24.763511</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710616</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 13:14:44.000513</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "834778       UK  2017-01-14 23:08:43.304998    control     old_page   \n",
       "928468       US  2017-01-23 14:44:16.387854  treatment     new_page   \n",
       "822059       UK  2017-01-16 14:04:14.719771  treatment     new_page   \n",
       "711597       UK  2017-01-22 03:14:24.763511    control     old_page   \n",
       "710616       UK  2017-01-16 13:14:44.000513  treatment     new_page   \n",
       "\n",
       "         converted  intercept  new_page  old_page  ab_page  \n",
       "user_id                                                     \n",
       "834778           0          1         0         1        0  \n",
       "928468           0          1         1         0        1  \n",
       "822059           1          1         1         0        1  \n",
       "711597           0          1         0         1        0  \n",
       "710616           0          1         1         0        1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_df = pd.read_csv('./countries.csv')\n",
    "df_new = countries_df.set_index('user_id').join(df2.set_index('user_id'), how='inner')\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UK', 'US', 'CA'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>new_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "      <th>CA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834778</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-14 23:08:43.304998</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928468</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-23 14:44:16.387854</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822059</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 14:04:14.719771</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711597</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-22 03:14:24.763511</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710616</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 13:14:44.000513</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "834778       UK  2017-01-14 23:08:43.304998    control     old_page   \n",
       "928468       US  2017-01-23 14:44:16.387854  treatment     new_page   \n",
       "822059       UK  2017-01-16 14:04:14.719771  treatment     new_page   \n",
       "711597       UK  2017-01-22 03:14:24.763511    control     old_page   \n",
       "710616       UK  2017-01-16 13:14:44.000513  treatment     new_page   \n",
       "\n",
       "         converted  intercept  new_page  old_page  ab_page  UK  US  CA  \n",
       "user_id                                                                 \n",
       "834778           0          1         0         1        0   0   1   0  \n",
       "928468           0          1         1         0        1   0   0   1  \n",
       "822059           1          1         1         0        1   0   1   0  \n",
       "711597           0          1         0         1        0   0   1   0  \n",
       "710616           0          1         1         0        1   0   1   0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[['UK', 'US', 'CA']] = pd.get_dummies(df_new['country'])\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>new_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834778</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-14 23:08:43.304998</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928468</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-23 14:44:16.387854</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822059</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 14:04:14.719771</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711597</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-22 03:14:24.763511</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710616</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 13:14:44.000513</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "834778       UK  2017-01-14 23:08:43.304998    control     old_page   \n",
       "928468       US  2017-01-23 14:44:16.387854  treatment     new_page   \n",
       "822059       UK  2017-01-16 14:04:14.719771  treatment     new_page   \n",
       "711597       UK  2017-01-22 03:14:24.763511    control     old_page   \n",
       "710616       UK  2017-01-16 13:14:44.000513  treatment     new_page   \n",
       "\n",
       "         converted  intercept  new_page  old_page  ab_page  UK  US  \n",
       "user_id                                                             \n",
       "834778           0          1         0         1        0   0   1  \n",
       "928468           0          1         1         0        1   0   0  \n",
       "822059           1          1         1         0        1   0   1  \n",
       "711597           0          1         0         1        0   0   1  \n",
       "710616           0          1         1         0        1   0   1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_new.drop('CA',axis=1)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 11 Oct 2020</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>23:36:47</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9893</td> <td>    0.009</td> <td> -223.763</td> <td> 0.000</td> <td>   -2.007</td> <td>   -1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>new_page</th>  <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>   -0.0408</td> <td>    0.027</td> <td>   -1.516</td> <td> 0.130</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.743</td> <td> 0.457</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Sun, 11 Oct 2020   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        23:36:47   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9893      0.009   -223.763      0.000      -2.007      -1.972\n",
       "new_page      -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "UK            -0.0408      0.027     -1.516      0.130      -0.093       0.012\n",
       "US             0.0099      0.013      0.743      0.457      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['intercept'] = 1\n",
    "logit_mod2 = sm.Logit(df_new['converted'], df_new[['intercept','new_page','UK','US']])\n",
    "results2 = logit_mod2.fit()\n",
    "results2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9851119396030626, 1.0519020483004984, 1.0416437559600236)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.0150),np.exp(0.0506),np.exp(0.0408)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.015113064615719"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.exp(-0.0150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that:\n",
    "\n",
    "1. For each 1 unit decrease in new_page, convert is ~1.02 times more likely to happen, holding all other varible constant.\n",
    "\n",
    "2. For each 1 unit increase in UK, convert is ~1.05 times more likely to happen, holding all other varible constant.\n",
    "\n",
    "3. For each 1 unit increase in US, convert is ~1.04 times more likely to happen, holding all other varible constant.\n",
    "\n",
    "> We conclude that countries dont have an impact on conversion rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Though we have now looked at the individual factors of country and page on conversion, we would now like to look at an interaction between page and country to see if it has significant effect on conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290578</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     5</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 11 Oct 2020</td> <th>  Pseudo R-squ.:     </th>  <td>3.482e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>23:36:48</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1920</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>   <td>   -1.9865</td> <td>    0.010</td> <td> -206.344</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>new_page</th>    <td>   -0.0206</td> <td>    0.014</td> <td>   -1.505</td> <td> 0.132</td> <td>   -0.047</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK_new_page</th> <td>   -0.0469</td> <td>    0.054</td> <td>   -0.872</td> <td> 0.383</td> <td>   -0.152</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US_new_page</th> <td>    0.0314</td> <td>    0.027</td> <td>    1.181</td> <td> 0.238</td> <td>   -0.021</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>          <td>   -0.0175</td> <td>    0.038</td> <td>   -0.465</td> <td> 0.642</td> <td>   -0.091</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>          <td>   -0.0057</td> <td>    0.019</td> <td>   -0.306</td> <td> 0.760</td> <td>   -0.043</td> <td>    0.031</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290578\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Sun, 11 Oct 2020   Pseudo R-squ.:               3.482e-05\n",
       "Time:                        23:36:48   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1920\n",
       "===============================================================================\n",
       "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "intercept      -1.9865      0.010   -206.344      0.000      -2.005      -1.968\n",
       "new_page       -0.0206      0.014     -1.505      0.132      -0.047       0.006\n",
       "UK_new_page    -0.0469      0.054     -0.872      0.383      -0.152       0.059\n",
       "US_new_page     0.0314      0.027      1.181      0.238      -0.021       0.084\n",
       "UK             -0.0175      0.038     -0.465      0.642      -0.091       0.056\n",
       "US             -0.0057      0.019     -0.306      0.760      -0.043       0.031\n",
       "===============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new intereacton variable between new page and US&UK\n",
    "df_new['UK_new_page'] = df_new['new_page']* df_new['UK']\n",
    "df_new['US_new_page'] = df_new['new_page']* df_new['US']\n",
    "\n",
    "#Create logistic regression for the interaction variable between new page and country using dummy variable\n",
    "logit_mod3 = sm.Logit(df_new['converted'], df_new[['intercept','new_page','UK_new_page','US_new_page','UK','US']])\n",
    "results3 = logit_mod3.fit()\n",
    "results3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept      0.137178\n",
       "new_page       0.979646\n",
       "UK_new_page    0.954198\n",
       "US_new_page    1.031896\n",
       "UK             0.982625\n",
       "US             0.994272\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(results3.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe from the above results that :\n",
    "\n",
    "1. We can see the coefficients for **UK_new_page** and **US_new_page** are different from the coefficient of **new_page**.\n",
    "\n",
    "2. Only intercept's p-value=0 is less than 0.05, which is statistically significant enough for converted rate. Other variables in the summary are not statistically significant. \n",
    "\n",
    "3. Z-score for all X variables are not large enough to be significant for predicting converted rate. \n",
    "\n",
    "4. For each 1 unit increase in new_page, convert is ~0.93 times more likely to happen, holding all other varible constant.\n",
    "\n",
    "> We conclude that the country a user lives in is not significant on the converted rate considering the page the user land in. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra - Model Diagnostics section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import sklearn model to split, test and score data,and fit data model \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>new_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "      <th>UK_new_page</th>\n",
       "      <th>US_new_page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834778</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-14 23:08:43.304998</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928468</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-23 14:44:16.387854</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822059</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 14:04:14.719771</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711597</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-22 03:14:24.763511</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710616</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 13:14:44.000513</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "834778       UK  2017-01-14 23:08:43.304998    control     old_page   \n",
       "928468       US  2017-01-23 14:44:16.387854  treatment     new_page   \n",
       "822059       UK  2017-01-16 14:04:14.719771  treatment     new_page   \n",
       "711597       UK  2017-01-22 03:14:24.763511    control     old_page   \n",
       "710616       UK  2017-01-16 13:14:44.000513  treatment     new_page   \n",
       "\n",
       "         converted  intercept  new_page  old_page  ab_page  UK  US  \\\n",
       "user_id                                                              \n",
       "834778           0          1         0         1        0   0   1   \n",
       "928468           0          1         1         0        1   0   0   \n",
       "822059           1          1         1         0        1   0   1   \n",
       "711597           0          1         0         1        0   0   1   \n",
       "710616           0          1         1         0        1   0   1   \n",
       "\n",
       "         UK_new_page  US_new_page  \n",
       "user_id                            \n",
       "834778             0            0  \n",
       "928468             0            0  \n",
       "822059             0            1  \n",
       "711597             0            0  \n",
       "710616             0            1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2826081036986245e-05\n"
     ]
    }
   ],
   "source": [
    "#Define X and Y variable \n",
    "x = df_new[['new_page','UK_new_page','US_new_page','UK','US']]\n",
    "y = df_new['converted']\n",
    "        \n",
    "#Split data into train and test data then fit the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "logit_mod4=LinearRegression()\n",
    "logit_mod4.fit(X_train,y_train) \n",
    "print (logit_mod4.score(X_train,y_train) )\n",
    "\n",
    "# The score result or the coefficient of determination R^2 of the prediction is very low, \n",
    "#which mean the page and country dataset are not a good fit to predit converted rate .\n",
    "\n",
    "# Please note that it is meaningless here to try to use a classification metric (accuracy) \n",
    "#in a regression (i.e. numeric prediction) model.It will give an error for this\n",
    "#theoretical and not computational issue when you try running the below code and importing the relevant library.\n",
    "#from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "#y_preds = logit_mod4.predict()\n",
    "#print(accuracy_score(y_te))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions\n",
    "\n",
    ">In part I, we were first making use of simple probabilities and we observed approximately the same probability regardless wherether we are in the control or treatement group which explain why our overall conversion propability regardless of the page is ~0.12 too so we concluded that there isnt sufficient evidence to say that the new treatment page leads to more conversions.\n",
    "\n",
    ">In part II, we decided to implement an A/B test and we observed that $p_{old}$ > $alpha$ with Type I error rate of 5%  and the z-score is lower than the critical value of ~1.96 so we failed to reject H0 ($p_{new}$ <= $p_{old}$) and we concluded that the conversion rates of the old and new pages are the same.\n",
    "\n",
    ">In part III, we decided to implement a logistic regression model on the dataset where we failed again to reject the null. We also added another effect based on which country a user lives onto our regression model and concluded that the country is not significant on the converted rate considering the page the user land on. \n",
    "\n",
    ">To go above and beyond, we may try to add the influences associated with time(timestamp variable) on conversion as previously mentioned where 4 dummy variables would be created for different aspects of the time (Morning,Afternoon,Evening and Night). Correctly implementing and interpreting the results would be good for our analysis. However, we should keep in mind that adding more terms to our model other than time will make it more complex, take away the ease of interpreting coefficients and might require high order terms if the new terms are dependable on the independent variable .\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
